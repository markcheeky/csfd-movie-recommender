{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "revised-manufacturer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import collections\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from typing import Any, Dict, List, Tuple, Union\n",
    "from pathlib import Path\n",
    "\n",
    "# from recommend.utils import PROJ_ROOT\n",
    "from pathlib import Path\n",
    "PROJ_ROOT =  \"../../../\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "official-starter",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "elder-tradition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creators2list(creators : str, top_n_actors : int = 3) -> List[str]:\n",
    "    \"\"\"Returns a list of `top_n_actors`, director, and a composer.\"\"\"\n",
    "    result = []\n",
    "    \n",
    "    if 'Hrají' in creators:\n",
    "        result = creators['Hrají'][:top_n_actors]\n",
    "        result = list(map(lambda x: x[1], result))\n",
    "\n",
    "    if 'Režie' in creators:\n",
    "        result += [creators['Režie'][0][1]]\n",
    "    if 'Hudba' in creators:\n",
    "        result += [creators['Hudba'][0][1]]\n",
    "    return result\n",
    "\n",
    "\n",
    "def analyse_freq(list_of_lists : List[List[Any]]) -> List[Tuple[Any, int]]:\n",
    "    \"\"\"\n",
    "    Counts occurences of items in a list of lists\n",
    "    and returns them in descending order as tuples <item, count>.\"\"\"\n",
    "\n",
    "    flat_list = [item for sublist in list_of_lists for item in sublist]\n",
    "    counter = collections.Counter(flat_list)\n",
    "    return counter.most_common(len(counter))\n",
    "\n",
    "\n",
    "def get_value(df : pd.DataFrame, movie_id : str, col : str) -> Any:\n",
    "    \"\"\"Retrieves a value in a cell specified by `col` for movie with ID `movie_id`\"\"\"\n",
    "    return df.loc[df['movie_id'] == m_id][col].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-gilbert",
   "metadata": {},
   "source": [
    "### Czech stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "approximate-engineer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python3.1\n",
    "''' Czech stemmer\n",
    "Copyright © 2010 Luís Gomes <luismsgomes@gmail.com>.\n",
    "\n",
    "Ported from the Java implementation available at:\n",
    "    http://members.unine.ch/jacques.savoy/clef/index.html\n",
    "\n",
    "'''\n",
    "import re\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "def cz_stem(word, aggressive=False):\n",
    "    if not re.match(\"^\\\\w+$\", word):\n",
    "        return word\n",
    "    if not word.islower() and not word.istitle() and not word.isupper():\n",
    "        #print(\"warning: skipping word with mixed case: {}\".format(word),\n",
    "              #file=sys.stderr)\n",
    "        return word\n",
    "    s = word.lower() # all our pattern matching is done in lowercase\n",
    "    s = _remove_case(s)\n",
    "    s = _remove_possessives(s)\n",
    "    if aggressive:\n",
    "        s = _remove_comparative(s)\n",
    "        s = _remove_diminutive(s)\n",
    "        s = _remove_augmentative(s)\n",
    "        s = _remove_derivational(s)\n",
    "    if word.isupper():\n",
    "        return s.upper()\n",
    "    if word.istitle():\n",
    "        return s.title()\n",
    "    return s\n",
    "\n",
    "def _remove_case(word):\n",
    "    if len(word) > 7 and word.endswith(\"atech\"):\n",
    "        return word[:-5]\n",
    "    if len(word) > 6:\n",
    "        if word.endswith(\"ětem\"):\n",
    "            return _palatalise(word[:-3])\n",
    "        if word.endswith(\"atům\"):\n",
    "            return word[:-4]\n",
    "    if len(word) > 5:\n",
    "        if word[-3:] in {\"ech\", \"ich\", \"ích\", \"ého\", \"ěmi\", \"emi\", \"ému\",\n",
    "                         \"ete\", \"eti\", \"iho\", \"ího\", \"ími\", \"imu\"}:\n",
    "            return _palatalise(word[:-2])\n",
    "        if word[-3:] in {\"ách\", \"ata\", \"aty\", \"ých\", \"ama\", \"ami\",\n",
    "                         \"ové\", \"ovi\", \"ými\"}:\n",
    "            return word[:-3]\n",
    "    if len(word) > 4:\n",
    "        if word.endswith(\"em\"):\n",
    "            return _palatalise(word[:-1])\n",
    "        if word[-2:] in {\"es\", \"ém\", \"ím\"}:\n",
    "            return _palatalise(word[:-2])\n",
    "        if word[-2:] in {\"ům\", \"at\", \"ám\", \"os\", \"us\", \"ým\", \"mi\", \"ou\"}:\n",
    "            return word[:-2]\n",
    "    if len(word) > 3:\n",
    "        if word[-1] in \"eiíě\":\n",
    "            return _palatalise(word)\n",
    "        if word[-1] in \"uyůaoáéý\":\n",
    "            return word[:-1]\n",
    "    return word\n",
    "\n",
    "def _remove_possessives(word):\n",
    "    if len(word) > 5:\n",
    "        if word[-2:] in {\"ov\", \"ův\"}:\n",
    "            return word[:-2]\n",
    "        if word.endswith(\"in\"):\n",
    "            return _palatalise(word[:-1])\n",
    "    return word\n",
    "\n",
    "def _remove_comparative(word):\n",
    "    if len(word) > 5:\n",
    "        if word[-3:] in {\"ejš\", \"ějš\"}:\n",
    "            return _palatalise(word[:-2])\n",
    "    return word\n",
    "\n",
    "def _remove_diminutive(word):\n",
    "    if len(word) > 7 and word.endswith(\"oušek\"):\n",
    "        return word[:-5]\n",
    "    if len(word) > 6:\n",
    "        if word[-4:] in {\"eček\", \"éček\", \"iček\", \"íček\", \"enek\", \"ének\",\n",
    "                         \"inek\", \"ínek\"}:\n",
    "            return _palatalise(word[:-3])\n",
    "        if word[-4:] in {\"áček\", \"aček\", \"oček\", \"uček\", \"anek\", \"onek\",\n",
    "                         \"unek\", \"ánek\"}:\n",
    "            return _palatalise(word[:-4])\n",
    "    if len(word) > 5:\n",
    "        if word[-3:] in {\"ečk\", \"éčk\", \"ičk\", \"íčk\", \"enk\", \"énk\",\n",
    "                         \"ink\", \"ínk\"}:\n",
    "            return _palatalise(word[:-3])\n",
    "        if word[-3:] in {\"áčk\", \"ačk\", \"očk\", \"učk\", \"ank\", \"onk\",\n",
    "                         \"unk\", \"átk\", \"ánk\", \"ušk\"}:\n",
    "            return word[:-3]\n",
    "    if len(word) > 4:\n",
    "        if word[-2:] in {\"ek\", \"ék\", \"ík\", \"ik\"}:\n",
    "            return _palatalise(word[:-1])\n",
    "        if word[-2:] in {\"ák\", \"ak\", \"ok\", \"uk\"}:\n",
    "            return word[:-1]\n",
    "    if len(word) > 3 and word[-1] == \"k\":\n",
    "        return word[:-1]\n",
    "    return word\n",
    "\n",
    "def _remove_augmentative(word):\n",
    "    if len(word) > 6 and word.endswith(\"ajzn\"):\n",
    "        return word[:-4]\n",
    "    if len(word) > 5 and word[-3:] in {\"izn\", \"isk\"}:\n",
    "        return _palatalise(word[:-2])\n",
    "    if len(word) > 4 and word.endswith(\"ák\"):\n",
    "        return word[:-2]\n",
    "    return word\n",
    "\n",
    "def _remove_derivational(word):\n",
    "    if len(word) > 8 and word.endswith(\"obinec\"):\n",
    "        return word[:-6]\n",
    "    if len(word) > 7:\n",
    "        if word.endswith(\"ionář\"):\n",
    "            return _palatalise(word[:-4])\n",
    "        if word[-5:] in {\"ovisk\", \"ovstv\", \"ovišt\", \"ovník\"}:\n",
    "            return word[:-5]\n",
    "    if len(word) > 6:\n",
    "        if word[-4:] in {\"ásek\", \"loun\", \"nost\", \"teln\", \"ovec\", \"ovík\",\n",
    "                         \"ovtv\", \"ovin\", \"štin\"}:\n",
    "            return word[:-4]\n",
    "        if word[-4:] in {\"enic\", \"inec\", \"itel\"}:\n",
    "            return _palatalise(word[:-3])\n",
    "    if len(word) > 5:\n",
    "        if word.endswith(\"árn\"):\n",
    "            return word[:-3]\n",
    "        if word[-3:] in {\"ěnk\", \"ián\", \"ist\", \"isk\", \"išt\", \"itb\", \"írn\"}:\n",
    "            return _palatalise(word[:-2])\n",
    "        if word[-3:] in {\"och\", \"ost\", \"ovn\", \"oun\", \"out\", \"ouš\",\n",
    "                         \"ušk\", \"kyn\", \"čan\", \"kář\", \"néř\", \"ník\",\n",
    "                         \"ctv\", \"stv\"}:\n",
    "            return word[:-3]\n",
    "    if len(word) > 4:\n",
    "        if word[-2:] in {\"áč\", \"ač\", \"án\", \"an\", \"ář\", \"as\"}:\n",
    "            return word[:-2]\n",
    "        if word[-2:] in {\"ec\", \"en\", \"ěn\", \"éř\", \"íř\", \"ic\", \"in\", \"ín\",\n",
    "                         \"it\", \"iv\"}:\n",
    "            return _palatalise(word[:-1])\n",
    "        if word[-2:] in {\"ob\", \"ot\", \"ov\", \"oň\", \"ul\", \"yn\", \"čk\", \"čn\",\n",
    "                         \"dl\", \"nk\", \"tv\", \"tk\", \"vk\"}:\n",
    "            return word[:-2]\n",
    "    if len(word) > 3 and word[-1] in \"cčklnt\":\n",
    "        return word[:-1]\n",
    "    return word\n",
    "\n",
    "def _palatalise(word):\n",
    "    if word[-2:] in {\"ci\", \"ce\", \"či\", \"če\"}:\n",
    "        return word[:-2] + \"k\"\n",
    "\n",
    "    if word[-2:] in {\"zi\", \"ze\", \"ži\", \"že\"}:\n",
    "        return word[:-2] + \"h\"\n",
    "\n",
    "    if word[-3:] in {\"čtě\", \"čti\", \"čtí\"}:\n",
    "        return word[:-3] + \"ck\"\n",
    "\n",
    "    if word[-3:] in {\"ště\", \"šti\", \"ští\"}:\n",
    "        return word[:-3] + \"sk\"\n",
    "    return word[:-1]\n",
    "\n",
    "\"\"\"\n",
    "if __name__ == '__main__':\n",
    "    if len(sys.argv) != 2 or sys.argv[1] not in (\"light\", \"aggressive\"):\n",
    "        sys.exit(\"usage: {} light|aggressive\".format(sys.argv[0]))\n",
    "    aggressive = sys.argv[1] == \"aggressive\"\n",
    "    for line in sys.stdin:\n",
    "        print(*[cz_stem(word, aggressive=aggressive)\n",
    "                for word in line.split()])\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-constitutional",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "latin-wrapping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>genres</th>\n",
       "      <th>countries</th>\n",
       "      <th>year</th>\n",
       "      <th>creators</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>230421-houbicky</th>\n",
       "      <td>Houbičky</td>\n",
       "      <td>Partička amerických teenagerů, která si vyrazi...</td>\n",
       "      <td>[Horor, Thriller]</td>\n",
       "      <td>[Irsko, Velká Británie, Dánsko]</td>\n",
       "      <td>2007</td>\n",
       "      <td>[Lindsey Haun, Jack Huston, Max Kasch, Paddy B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10789-prvni-liga</th>\n",
       "      <td>První liga</td>\n",
       "      <td>V nejvyšší lize získávají hráči baseballu boha...</td>\n",
       "      <td>[Komedie, Sportovní]</td>\n",
       "      <td>[USA]</td>\n",
       "      <td>1989</td>\n",
       "      <td>[Tom Berenger, Charlie Sheen, Corbin Bernsen, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235032-yes-man</th>\n",
       "      <td>Yes Man</td>\n",
       "      <td>Carl Allen je zatrpklý bankovní úředník, který...</td>\n",
       "      <td>[Komedie, Romantický]</td>\n",
       "      <td>[USA]</td>\n",
       "      <td>2008</td>\n",
       "      <td>[Jim Carrey, Zooey Deschanel, Bradley Cooper, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       title  \\\n",
       "movie_id                       \n",
       "230421-houbicky     Houbičky   \n",
       "10789-prvni-liga  První liga   \n",
       "235032-yes-man       Yes Man   \n",
       "\n",
       "                                                        description  \\\n",
       "movie_id                                                              \n",
       "230421-houbicky   Partička amerických teenagerů, která si vyrazi...   \n",
       "10789-prvni-liga  V nejvyšší lize získávají hráči baseballu boha...   \n",
       "235032-yes-man    Carl Allen je zatrpklý bankovní úředník, který...   \n",
       "\n",
       "                                 genres                        countries  \\\n",
       "movie_id                                                                   \n",
       "230421-houbicky       [Horor, Thriller]  [Irsko, Velká Británie, Dánsko]   \n",
       "10789-prvni-liga   [Komedie, Sportovní]                            [USA]   \n",
       "235032-yes-man    [Komedie, Romantický]                            [USA]   \n",
       "\n",
       "                  year                                           creators  \n",
       "movie_id                                                                   \n",
       "230421-houbicky   2007  [Lindsey Haun, Jack Huston, Max Kasch, Paddy B...  \n",
       "10789-prvni-liga  1989  [Tom Berenger, Charlie Sheen, Corbin Bernsen, ...  \n",
       "235032-yes-man    2008  [Jim Carrey, Zooey Deschanel, Bradley Cooper, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kinghome</td>\n",
       "      <td>230421-houbicky</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2011-11-13</td>\n",
       "      <td>Hodnocení některých šašků tady opravdu necháp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SimonShot</td>\n",
       "      <td>230421-houbicky</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2012-12-19</td>\n",
       "      <td>Tento snímek je zajímavý už jenom tím že se n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blackend</td>\n",
       "      <td>230421-houbicky</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2010-09-04</td>\n",
       "      <td>Pohoda a vzhledem k dobré atmosféře a nízkému...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    username         movie_id  stars       date  \\\n",
       "0   kinghome  230421-houbicky    5.0 2011-11-13   \n",
       "1  SimonShot  230421-houbicky    5.0 2012-12-19   \n",
       "2   blackend  230421-houbicky    5.0 2010-09-04   \n",
       "\n",
       "                                             comment  \n",
       "0   Hodnocení některých šašků tady opravdu necháp...  \n",
       "1   Tento snímek je zajímavý už jenom tím že se n...  \n",
       "2   Pohoda a vzhledem k dobré atmosféře a nízkému...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_pickle(PROJ_ROOT + 'data/movies.pkl')\n",
    "ratings = pd.read_pickle(PROJ_ROOT + 'data/ratings.pkl')\n",
    "\n",
    "\n",
    "# Drop irrelevant columns\n",
    "movies = movies.drop(columns=['kind', 'length', 'poster', 'foreign_titles'])\n",
    "\n",
    "# Convert creators column to list of creators\n",
    "movies['creators'] = movies['creators'].apply(creators2list)\n",
    "#movies.reset_index(inplace=True) # causes trouble with join\n",
    "\n",
    "display(movies.head(3))\n",
    "ratings.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "suitable-welcome",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>genres</th>\n",
       "      <th>countries</th>\n",
       "      <th>year</th>\n",
       "      <th>creators</th>\n",
       "      <th>avg_stars</th>\n",
       "      <th>num_ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75613-hercule-poirot_498504-serie-9</td>\n",
       "      <td>Hercule Poirot</td>\n",
       "      <td>Malý belgický detektiv Hercule Poirot (David S...</td>\n",
       "      <td>[Krimi, Drama, Mysteriózní, Thriller]</td>\n",
       "      <td>[Velká Británie]</td>\n",
       "      <td>(1989–2013)</td>\n",
       "      <td>[David Suchet, Hugh Fraser, Philip Jackson, Ed...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>613789-obeti</td>\n",
       "      <td>Oběti</td>\n",
       "      <td>Na televizní obrazovku se vrací cyklus  o lide...</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>[Česko]</td>\n",
       "      <td>(1999–2008)</td>\n",
       "      <td>[Zbyněk Fric, Karel Zima, Libor Žídek, Petr Sl...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75613-hercule-poirot_498507-serie-12</td>\n",
       "      <td>Hercule Poirot</td>\n",
       "      <td>Malý belgický detektiv Hercule Poirot (David S...</td>\n",
       "      <td>[Krimi, Drama, Mysteriózní, Thriller]</td>\n",
       "      <td>[Velká Británie]</td>\n",
       "      <td>(1989–2013)</td>\n",
       "      <td>[David Suchet, Hugh Fraser, Philip Jackson, Ed...</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>350930-krtek</td>\n",
       "      <td>Krtek</td>\n",
       "      <td></td>\n",
       "      <td>[Animovaný, Dobrodružný]</td>\n",
       "      <td>[Česko, Finsko]</td>\n",
       "      <td>2011</td>\n",
       "      <td>[Zdeněk Miler, Wiliam Bukový]</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33863-bajaja</td>\n",
       "      <td>Bajaja</td>\n",
       "      <td>Jiří Trnka natočil v roce 1950 volně podle poh...</td>\n",
       "      <td>[Animovaný, Loutkový, Pohádka]</td>\n",
       "      <td>[Československo]</td>\n",
       "      <td>1950</td>\n",
       "      <td>[Jiří Trnka, Václav Trojan]</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8669</th>\n",
       "      <td>232938-hobit-neocekavana-cesta</td>\n",
       "      <td>Hobit: Neočekávaná cesta</td>\n",
       "      <td>Film sleduje cestu hlavní postavy Bilbo Pytlík...</td>\n",
       "      <td>[Dobrodružný, Fantasy]</td>\n",
       "      <td>[USA, Nový Zéland]</td>\n",
       "      <td>2012</td>\n",
       "      <td>[Martin Freeman, Ian McKellen, Richard Armitag...</td>\n",
       "      <td>3.953150</td>\n",
       "      <td>3159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>227786-interstellar</td>\n",
       "      <td>Interstellar</td>\n",
       "      <td>Příběh se odehrává v nepříliš vzdálené budoucn...</td>\n",
       "      <td>[Sci-Fi, Dobrodružný, Drama]</td>\n",
       "      <td>[USA, Velká Británie, Kanada]</td>\n",
       "      <td>2014</td>\n",
       "      <td>[Matthew McConaughey, Anne Hathaway, Jessica C...</td>\n",
       "      <td>4.072779</td>\n",
       "      <td>3174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>223734-temny-rytir</td>\n",
       "      <td>Temný rytíř</td>\n",
       "      <td>Další Batmanovo dobrodružství začíná. Jeho pro...</td>\n",
       "      <td>[Akční, Drama, Krimi, Thriller]</td>\n",
       "      <td>[USA, Velká Británie]</td>\n",
       "      <td>2008</td>\n",
       "      <td>[Christian Bale, Heath Ledger, Aaron Eckhart, ...</td>\n",
       "      <td>4.559151</td>\n",
       "      <td>3770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>254156-pocatek</td>\n",
       "      <td>Počátek</td>\n",
       "      <td>Dom Cobb (Leonardo DiCaprio) je velmi zkušený ...</td>\n",
       "      <td>[Akční, Sci-Fi, Thriller, Mysteriózní, Dobrodr...</td>\n",
       "      <td>[USA, Velká Británie]</td>\n",
       "      <td>2010</td>\n",
       "      <td>[Leonardo DiCaprio, Joseph Gordon-Levitt, Elli...</td>\n",
       "      <td>4.368000</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>228329-avatar</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>Avatar před námi otevírá neuvěřitelný svět za ...</td>\n",
       "      <td>[Akční, Dobrodružný, Sci-Fi, Fantasy]</td>\n",
       "      <td>[USA, Velká Británie]</td>\n",
       "      <td>2009</td>\n",
       "      <td>[Sam Worthington, Zoe Saldana, Stephen Lang, J...</td>\n",
       "      <td>4.008142</td>\n",
       "      <td>4790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8674 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  movie_id                     title  \\\n",
       "0      75613-hercule-poirot_498504-serie-9            Hercule Poirot   \n",
       "1                             613789-obeti                     Oběti   \n",
       "2     75613-hercule-poirot_498507-serie-12            Hercule Poirot   \n",
       "3                             350930-krtek                     Krtek   \n",
       "4                             33863-bajaja                    Bajaja   \n",
       "...                                    ...                       ...   \n",
       "8669        232938-hobit-neocekavana-cesta  Hobit: Neočekávaná cesta   \n",
       "8670                   227786-interstellar              Interstellar   \n",
       "8671                    223734-temny-rytir               Temný rytíř   \n",
       "8672                        254156-pocatek                   Počátek   \n",
       "8673                         228329-avatar                    Avatar   \n",
       "\n",
       "                                            description  \\\n",
       "0     Malý belgický detektiv Hercule Poirot (David S...   \n",
       "1     Na televizní obrazovku se vrací cyklus  o lide...   \n",
       "2     Malý belgický detektiv Hercule Poirot (David S...   \n",
       "3                                                         \n",
       "4     Jiří Trnka natočil v roce 1950 volně podle poh...   \n",
       "...                                                 ...   \n",
       "8669  Film sleduje cestu hlavní postavy Bilbo Pytlík...   \n",
       "8670  Příběh se odehrává v nepříliš vzdálené budoucn...   \n",
       "8671  Další Batmanovo dobrodružství začíná. Jeho pro...   \n",
       "8672  Dom Cobb (Leonardo DiCaprio) je velmi zkušený ...   \n",
       "8673  Avatar před námi otevírá neuvěřitelný svět za ...   \n",
       "\n",
       "                                                 genres  \\\n",
       "0                 [Krimi, Drama, Mysteriózní, Thriller]   \n",
       "1                                               [Drama]   \n",
       "2                 [Krimi, Drama, Mysteriózní, Thriller]   \n",
       "3                              [Animovaný, Dobrodružný]   \n",
       "4                        [Animovaný, Loutkový, Pohádka]   \n",
       "...                                                 ...   \n",
       "8669                             [Dobrodružný, Fantasy]   \n",
       "8670                       [Sci-Fi, Dobrodružný, Drama]   \n",
       "8671                    [Akční, Drama, Krimi, Thriller]   \n",
       "8672  [Akční, Sci-Fi, Thriller, Mysteriózní, Dobrodr...   \n",
       "8673              [Akční, Dobrodružný, Sci-Fi, Fantasy]   \n",
       "\n",
       "                          countries         year  \\\n",
       "0                  [Velká Británie]  (1989–2013)   \n",
       "1                           [Česko]  (1999–2008)   \n",
       "2                  [Velká Británie]  (1989–2013)   \n",
       "3                   [Česko, Finsko]         2011   \n",
       "4                  [Československo]         1950   \n",
       "...                             ...          ...   \n",
       "8669             [USA, Nový Zéland]         2012   \n",
       "8670  [USA, Velká Británie, Kanada]         2014   \n",
       "8671          [USA, Velká Británie]         2008   \n",
       "8672          [USA, Velká Británie]         2010   \n",
       "8673          [USA, Velká Británie]         2009   \n",
       "\n",
       "                                               creators  avg_stars  \\\n",
       "0     [David Suchet, Hugh Fraser, Philip Jackson, Ed...   5.000000   \n",
       "1     [Zbyněk Fric, Karel Zima, Libor Žídek, Petr Sl...   5.000000   \n",
       "2     [David Suchet, Hugh Fraser, Philip Jackson, Ed...   4.500000   \n",
       "3                         [Zdeněk Miler, Wiliam Bukový]   4.500000   \n",
       "4                           [Jiří Trnka, Václav Trojan]   4.285714   \n",
       "...                                                 ...        ...   \n",
       "8669  [Martin Freeman, Ian McKellen, Richard Armitag...   3.953150   \n",
       "8670  [Matthew McConaughey, Anne Hathaway, Jessica C...   4.072779   \n",
       "8671  [Christian Bale, Heath Ledger, Aaron Eckhart, ...   4.559151   \n",
       "8672  [Leonardo DiCaprio, Joseph Gordon-Levitt, Elli...   4.368000   \n",
       "8673  [Sam Worthington, Zoe Saldana, Stephen Lang, J...   4.008142   \n",
       "\n",
       "      num_ratings  \n",
       "0               1  \n",
       "1               1  \n",
       "2               2  \n",
       "3               2  \n",
       "4              14  \n",
       "...           ...  \n",
       "8669         3159  \n",
       "8670         3174  \n",
       "8671         3770  \n",
       "8672         4000  \n",
       "8673         4790  \n",
       "\n",
       "[8674 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get mean rating of each film \n",
    "avg_ratings = ratings[['movie_id', 'stars']].groupby(['movie_id']).mean()\n",
    "avg_ratings.rename(columns={'stars': 'avg_stars'}, inplace=True)\n",
    "\n",
    "# get rating count of each film\n",
    "count_ratings = ratings[['movie_id', 'stars']].groupby('movie_id').count()\n",
    "count_ratings.rename(columns={'stars': 'num_ratings'}, inplace=True)\n",
    "count_ratings\n",
    "\n",
    "# join with the movies database\n",
    "movie_db = movies.join(avg_ratings).join(count_ratings).sort_values(by='num_ratings')\n",
    "movie_db = movie_db.reset_index()\n",
    "movie_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-destination",
   "metadata": {},
   "source": [
    "\n",
    "# Recommendation Systems\n",
    "---\n",
    "## Base class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "compound-congo",
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "\n",
    "class RecSysBase(abc.ABC):\n",
    "    \"\"\"\n",
    "    Recommendation System Base class.\n",
    "    \n",
    "    The system should store a database of available movies.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, movies_df : pd.DataFrame):\n",
    "        self.movies_df = movies_df\n",
    "    \n",
    "    @property\n",
    "    def name(self):\n",
    "        return self.__class__.__name__\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def recommend(self, user_history : List[str], n : int = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Generates recommendations based on user's history of rated movies.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        user_history : List[str]\n",
    "            A list of movie ids a user has rated so far.\n",
    "            \n",
    "        n : int\n",
    "            The number of recommendations to return.\n",
    "            Default value None returns all movies from database.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            movie_id ~ movie ID\n",
    "            score_<class_name> ~ score of each movie\n",
    "        \"\"\"\n",
    "        ...\n",
    "\n",
    "    def get_candidate_movies(self, user_history : List[str]) -> pd.DataFrame:\n",
    "        \"\"\"Returns a list of candidates by filtering movies a user has already seen.\"\"\"\n",
    "        df = pd.concat([self.movies_df, self._ids2df(user_history, preserve_order=False)])\n",
    "        # convert to str because drop_duplicates does not work on dfs containing structures\n",
    "        return df.loc[df.astype(str).drop_duplicates(keep=False).index]\n",
    "\n",
    "    def _ids2df(self, movie_ids : List[str], preserve_order : bool = True) -> pd.DataFrame:\n",
    "        \"\"\"For a list of movie ids returns a dataframe compatible with `self.movies_df`\"\"\"        \n",
    "        if not preserve_order or len(movie_ids) == 0:\n",
    "            # faster variant but sorted as in self.movies_df \n",
    "            mask = self.movies_df['movie_id'].isin(movie_ids)\n",
    "            return self.movies_df.loc[mask]\n",
    "\n",
    "        df_list = []\n",
    "        for mid in movie_ids:\n",
    "            df_list.append(self.movies_df[self.movies_df['movie_id'] == mid])\n",
    "        return pd.concat(df_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-peeing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "alike-testimony",
   "metadata": {},
   "source": [
    "## Random recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "amber-saver",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class RandomRS(RecSysBase):\n",
    "    \"\"\"\n",
    "    System that recommends movies randomly.\n",
    "    \"\"\"\n",
    "    def __init__(self, movies_df : pd.DataFrame):\n",
    "        super(RandomRS, self).__init__(movies_df)\n",
    "\n",
    "    def recommend(self, user_history : List[str], n : int = 10, return_df : bool = False) -> List[str]:\n",
    "        \"\"\"\n",
    "        Recommends n random movies.\n",
    "        Movies from `user_history` do not appear in the recommendations.\n",
    "        \"\"\"\n",
    "        recommendations = self.get_candidate_movies(user_history).sample(n)\n",
    "        return recommendations if return_df else recommendations.movie_id\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "synthetic-albany",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>genres</th>\n",
       "      <th>countries</th>\n",
       "      <th>year</th>\n",
       "      <th>creators</th>\n",
       "      <th>avg_stars</th>\n",
       "      <th>num_ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8361</th>\n",
       "      <td>182363-million-dollar-baby</td>\n",
       "      <td>Million Dollar Baby</td>\n",
       "      <td>Mladá žena Maggie Fitzgeraldová osloví trenéra...</td>\n",
       "      <td>[Sportovní, Drama]</td>\n",
       "      <td>[USA]</td>\n",
       "      <td>2004</td>\n",
       "      <td>[Clint Eastwood, Hilary Swank, Morgan Freeman,...</td>\n",
       "      <td>4.499584</td>\n",
       "      <td>1201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4564</th>\n",
       "      <td>2435-rostaci</td>\n",
       "      <td>Rošťáci</td>\n",
       "      <td>Parta dětí na cestě za pokladem pirátů. Dobrod...</td>\n",
       "      <td>[Dobrodružný, Rodinný, Komedie]</td>\n",
       "      <td>[USA]</td>\n",
       "      <td>1985</td>\n",
       "      <td>[Sean Astin, Josh Brolin, Jeff Cohen, Richard ...</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4021</th>\n",
       "      <td>244311-the-belko-experiment</td>\n",
       "      <td>Experiment Belko</td>\n",
       "      <td>Běžný den v kanceláři se promění v děsivý boj ...</td>\n",
       "      <td>[Akční, Horor, Thriller]</td>\n",
       "      <td>[USA, Kolumbie]</td>\n",
       "      <td>2016</td>\n",
       "      <td>[Tony Goldwyn, Michael Rooker, David Dastmalch...</td>\n",
       "      <td>3.245614</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         movie_id                title  \\\n",
       "8361   182363-million-dollar-baby  Million Dollar Baby   \n",
       "4564                 2435-rostaci              Rošťáci   \n",
       "4021  244311-the-belko-experiment     Experiment Belko   \n",
       "\n",
       "                                            description  \\\n",
       "8361  Mladá žena Maggie Fitzgeraldová osloví trenéra...   \n",
       "4564  Parta dětí na cestě za pokladem pirátů. Dobrod...   \n",
       "4021  Běžný den v kanceláři se promění v děsivý boj ...   \n",
       "\n",
       "                               genres        countries  year  \\\n",
       "8361               [Sportovní, Drama]            [USA]  2004   \n",
       "4564  [Dobrodružný, Rodinný, Komedie]            [USA]  1985   \n",
       "4021         [Akční, Horor, Thriller]  [USA, Kolumbie]  2016   \n",
       "\n",
       "                                               creators  avg_stars  \\\n",
       "8361  [Clint Eastwood, Hilary Swank, Morgan Freeman,...   4.499584   \n",
       "4564  [Sean Astin, Josh Brolin, Jeff Cohen, Richard ...   3.750000   \n",
       "4021  [Tony Goldwyn, Michael Rooker, David Dastmalch...   3.245614   \n",
       "\n",
       "      num_ratings  \n",
       "8361         1201  \n",
       "4564          200  \n",
       "4021          171  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_rs = RandomRS(movie_db)\n",
    "\n",
    "rnd_rs.recommend([], 3, return_df=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-plant",
   "metadata": {},
   "source": [
    "## Recommendation based on movie popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "express-jurisdiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PopularityRS(RecSysBase):\n",
    "    \"\"\"\n",
    "    System recommends top n most popular movies a user has not rated yet.\n",
    "    \"\"\"\n",
    "    def __init__(self, movies_df : pd.DataFrame):\n",
    "        super(PopularityRS, self).__init__(movies_df)\n",
    "\n",
    "    def recommend(self, user_history : List[str], n : int = 10, return_df : bool = False) -> List[str]:\n",
    "        \"\"\"\n",
    "        Recommends n most rated movies a user has not yet seen.\n",
    "        \"\"\"\n",
    "        recommendations = self.get_candidate_movies(user_history).sort_values(by='num_ratings').tail(n)\n",
    "        return recommendations if return_df else recommendations.movie_id[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aging-sender",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>genres</th>\n",
       "      <th>countries</th>\n",
       "      <th>year</th>\n",
       "      <th>creators</th>\n",
       "      <th>avg_stars</th>\n",
       "      <th>num_ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>227786-interstellar</td>\n",
       "      <td>Interstellar</td>\n",
       "      <td>Příběh se odehrává v nepříliš vzdálené budoucn...</td>\n",
       "      <td>[Sci-Fi, Dobrodružný, Drama]</td>\n",
       "      <td>[USA, Velká Británie, Kanada]</td>\n",
       "      <td>2014</td>\n",
       "      <td>[Matthew McConaughey, Anne Hathaway, Jessica C...</td>\n",
       "      <td>4.072779</td>\n",
       "      <td>3174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>223734-temny-rytir</td>\n",
       "      <td>Temný rytíř</td>\n",
       "      <td>Další Batmanovo dobrodružství začíná. Jeho pro...</td>\n",
       "      <td>[Akční, Drama, Krimi, Thriller]</td>\n",
       "      <td>[USA, Velká Británie]</td>\n",
       "      <td>2008</td>\n",
       "      <td>[Christian Bale, Heath Ledger, Aaron Eckhart, ...</td>\n",
       "      <td>4.559151</td>\n",
       "      <td>3770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>254156-pocatek</td>\n",
       "      <td>Počátek</td>\n",
       "      <td>Dom Cobb (Leonardo DiCaprio) je velmi zkušený ...</td>\n",
       "      <td>[Akční, Sci-Fi, Thriller, Mysteriózní, Dobrodr...</td>\n",
       "      <td>[USA, Velká Británie]</td>\n",
       "      <td>2010</td>\n",
       "      <td>[Leonardo DiCaprio, Joseph Gordon-Levitt, Elli...</td>\n",
       "      <td>4.368000</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 movie_id         title  \\\n",
       "8670  227786-interstellar  Interstellar   \n",
       "8671   223734-temny-rytir   Temný rytíř   \n",
       "8672       254156-pocatek       Počátek   \n",
       "\n",
       "                                            description  \\\n",
       "8670  Příběh se odehrává v nepříliš vzdálené budoucn...   \n",
       "8671  Další Batmanovo dobrodružství začíná. Jeho pro...   \n",
       "8672  Dom Cobb (Leonardo DiCaprio) je velmi zkušený ...   \n",
       "\n",
       "                                                 genres  \\\n",
       "8670                       [Sci-Fi, Dobrodružný, Drama]   \n",
       "8671                    [Akční, Drama, Krimi, Thriller]   \n",
       "8672  [Akční, Sci-Fi, Thriller, Mysteriózní, Dobrodr...   \n",
       "\n",
       "                          countries  year  \\\n",
       "8670  [USA, Velká Británie, Kanada]  2014   \n",
       "8671          [USA, Velká Británie]  2008   \n",
       "8672          [USA, Velká Británie]  2010   \n",
       "\n",
       "                                               creators  avg_stars  \\\n",
       "8670  [Matthew McConaughey, Anne Hathaway, Jessica C...   4.072779   \n",
       "8671  [Christian Bale, Heath Ledger, Aaron Eckhart, ...   4.559151   \n",
       "8672  [Leonardo DiCaprio, Joseph Gordon-Levitt, Elli...   4.368000   \n",
       "\n",
       "      num_ratings  \n",
       "8670         3174  \n",
       "8671         3770  \n",
       "8672         4000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = ['228329-avatar']\n",
    "\n",
    "rs = PopularityRS(movie_db)\n",
    "\n",
    "rs.recommend(history, 3, return_df=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepared-better",
   "metadata": {},
   "source": [
    "## TF-IDF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "civic-variable",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stop_words\n",
    "from nltk.tokenize import word_tokenize\n",
    "from multiprocessing import get_context, Pool\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.matutils import cossim\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.similarities import SparseMatrixSimilarity\n",
    "from gensim.utils import simple_preprocess\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class TfidfRS(RecSysBase):\n",
    "    \"\"\"\n",
    "    System recommends unseen movies using TF-IDF\n",
    "    \"\"\"\n",
    "    def __init__(self, movies_df : pd.DataFrame):\n",
    "        super(TfidfRS, self).__init__(movies_df)\n",
    "        \n",
    "        # Document == movie title & description\n",
    "        documents = list(movies_df.title.astype(str) + ' ' + movies_df.description)\n",
    "        \n",
    "        # Build Dictionary\n",
    "        with get_context('fork').Pool(None) as pool:\n",
    "            doc_tokens = pool.imap(self.__class__._document_to_tokens, documents)\n",
    "            doc_tokens = tqdm(doc_tokens, desc='Building the dictionary', total=len(documents))\n",
    "            self.dictionary = Dictionary(doc_tokens)\n",
    "            self.__class__.DICTIONARY = self.dictionary\n",
    "        \n",
    "        # Build TF-IDF model\n",
    "        with get_context('fork').Pool(None) as pool:\n",
    "            #doc_bows = pool.imap(self.__class__._tokens_to_bag_of_words, self.__class__.doc_tokens)\n",
    "            doc_bows = pool.imap(self.__class__._document_to_bag_of_words, documents)\n",
    "            doc_bows = tqdm(doc_bows, desc='Building the TF-IDF model', total=len(documents))\n",
    "            self.tfidf_model = TfidfModel(doc_bows)\n",
    "            self.__class__.TFIDF_MODEL = self.tfidf_model\n",
    "\n",
    "        # Build the index\n",
    "        with get_context('fork').Pool(None) as pool:    \n",
    "            #doc_vectors = pool.imap(self.__class__._bow_to_tfidf_vector, self.doc_bows)\n",
    "            doc_vectors = pool.imap(self.__class__._document_to_tfidf_vector, documents)\n",
    "            doc_vectors = tqdm(doc_vectors, desc='Building the TF-IDF index', total=len(documents))\n",
    "            self.index = SparseMatrixSimilarity(doc_vectors, num_docs=len(documents), num_terms=len(self.dictionary))\n",
    "            \n",
    "        del self.__class__.DICTIONARY\n",
    "        del self.__class__.TFIDF_MODEL \n",
    "\n",
    "        self.index_to_movie_id = dict(enumerate(self.movies_df.movie_id.to_list()))\n",
    "\n",
    "    \n",
    "    def recommend(self, user_history : List[str], n : int = 10, return_df : bool = False) -> List[str]:\n",
    "        \"\"\"Recommends unseen movies using tfidf vectors and cosine similarity.\n",
    "        \n",
    "        TODO: Is it better to yield movies one by one or return a list / DF?\n",
    "        TODO: solve because `n` and `return_df` are currently not used\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        user_history : List[str]\n",
    "            A list of movie IDs\n",
    "        \"\"\"\n",
    "        # Take last k movies, join them into a single description and create a query.\n",
    "        k = 50 # TODO: should this be a customizable parameter? or should it be tuned?\n",
    "        last_k_movies = user_history[-k:]\n",
    "        query = ' '.join([self.get_description_with_id(mid) for mid in last_k_movies])\n",
    "        \n",
    "        self.__class__.DICTIONARY = self.dictionary\n",
    "        self.__class__.TFIDF_MODEL = self.tfidf_model\n",
    "\n",
    "        query_vector = self.__class__._document_to_tfidf_vector(query)\n",
    "        similarities = enumerate(self.index[query_vector])\n",
    "        similarities = sorted(similarities, key=lambda item: item[1], reverse=True)\n",
    "\n",
    "        for idx, sim in similarities:\n",
    "            movie_id = self.index_to_movie_id[idx]\n",
    "            if movie_id not in user_history:\n",
    "                yield movie_id, sim\n",
    "        \n",
    "        del self.__class__.DICTIONARY\n",
    "        del self.__class__.TFIDF_MODEL\n",
    "\n",
    "    @classmethod\n",
    "    def _document_to_tokens(cls, document: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Filters stop words and applies stemming on the given string.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : str\n",
    "            A simple string containing text to preprocess.\n",
    "        \"\"\"\n",
    "        tokens = word_tokenize(document.lower(), language='czech')\n",
    "        filtered = [w.strip(\",.:'?!()[]{}<>_\") for w in document.split() if w not in set(stop_words.get_stop_words('czech'))]\n",
    "        res = [cz_stem(word) for word in filtered]\n",
    "        return res\n",
    "    \n",
    "    @classmethod\n",
    "    def _document_to_bag_of_words(cls, document: str) -> List[Tuple[int, int]]:\n",
    "        return cls.DICTIONARY.doc2bow(cls._document_to_tokens(document))\n",
    "    \n",
    "    @classmethod\n",
    "    def _document_to_tfidf_vector(cls, document: str) -> List[Tuple[int, float]]:\n",
    "        return cls.TFIDF_MODEL[cls._document_to_bag_of_words(document)]\n",
    "\n",
    "    @classmethod\n",
    "    def _tokens_to_bag_of_words(cls, tokens: List[str]) -> List[Tuple[int, int]]:\n",
    "        return cls.DICTIONARY.doc2bow(tokens)\n",
    "    \n",
    "    @classmethod\n",
    "    def _bow_to_tfidf_vector(cls, bow: List[Tuple[int, int]]) -> List[Tuple[int, float]]:\n",
    "        return cls.TFIDF_MODEL[bow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "extra-tourist",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building the dictionary: 100%|██████████| 8674/8674 [00:06<00:00, 1253.31it/s]\n",
      "Building the TF-IDF model: 100%|██████████| 8674/8674 [00:05<00:00, 1484.43it/s]\n",
      "Building the TF-IDF index: 100%|██████████| 8674/8674 [00:07<00:00, 1087.89it/s]\n"
     ]
    }
   ],
   "source": [
    "rs_tfidf = TfidfRS(movie_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "wicked-template",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TfidfRS' object has no attribute 'get_description_with_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-fb84276792e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'1644-kmotr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'1645-kmotr-ii'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'9499-matrix'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'342231-lego-batman'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmovie_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrs_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecommend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{i+1}. {movie_id} ({sim:.4f})'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-ad52b019af37>\u001b[0m in \u001b[0;36mrecommend\u001b[0;34m(self, user_history, n, return_df)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;31m# TODO: should this be a customizable parameter? or should it be tuned?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mlast_k_movies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_description_with_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlast_k_movies\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDICTIONARY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-ad52b019af37>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;31m# TODO: should this be a customizable parameter? or should it be tuned?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mlast_k_movies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_description_with_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlast_k_movies\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDICTIONARY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TfidfRS' object has no attribute 'get_description_with_id'"
     ]
    }
   ],
   "source": [
    "history = ['1644-kmotr', '1645-kmotr-ii', '9499-matrix', '342231-lego-batman']\n",
    "\n",
    "for i, (movie_id, sim)  in enumerate(rs_tfidf.recommend(history)):\n",
    "    print(f'{i+1}. {movie_id} ({sim:.4f})')\n",
    "    if i == 15: break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-differential",
   "metadata": {},
   "source": [
    "## LSA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-parts",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czech-maximum",
   "metadata": {},
   "source": [
    "## Embeedding approaches\n",
    "\n",
    "### Headline embedding\n",
    "generate headlines and put it to the root_dir/data/headlines.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-introduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path\n",
    "sys.path.append('../../../../../Summarization') # Adam's meta repo\n",
    "\n",
    "from transformers import GPT2LMHeadModel\n",
    "# from utils import add_special_tokens, generate_one_summary_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-rehabilitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model_path = \"../../../../../Summarization/models_ext/noconotr3in1_tohead_eos_2021-10-18-11_26_58/checkpoint-181005\"  # Adam's meta repo\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "\n",
    "# put model into eval mode and on device\n",
    "model.eval()\n",
    "device = 'cuda' # 'cpu' alternatively\n",
    "model.to(device)\n",
    "\n",
    "# load and set tokenizer\n",
    "tokenizer_path = \"../../../../../gpt2czech/tokenizer/hf/model50257_LBF/\"  # Adam's meta repo\n",
    "tokenizer = add_special_tokens(tokenizer_path)\n",
    "tokenizer.model_max_length = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-tomorrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# for each description get a headline\n",
    "hdf = movie_db[[\"movie_id\", \"description\"]]\n",
    "headlines = []\n",
    "for i in range(len(movie_db[\"description\"]):\n",
    "    input_seq = hdf.iloc[i][\"description\"]\n",
    "    headlines.append(generate_one_summary_fast(input_seq, tokenizer, model, top_k=50, top_p=0.5, device=device, eos_stopping=True))\n",
    "\n",
    "hdf = hdf.head(len(headlines))[[\"movie_id\"]]\n",
    "hdf[\"headline\"] = headlines\n",
    "hdf.to_csv(\"../../../data/headlines.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "soviet-allah",
   "metadata": {},
   "source": [
    "generate embeddings to the headlines using Czert cased B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-funds",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForPreTraining\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-expense",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"UWB-AIR/Czert-B-base-cased\")\n",
    "model = AutoModelForPreTraining.from_pretrained(\"UWB-AIR/Czert-B-base-cased\")\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-china",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_headlines = pd.read_csv(\"../../../data/headlines.csv\")\n",
    "df_headlines.head(4)\n",
    "df_headlines.drop(columns=[\"Unnamed: 0.1\", \"Unnamed: 0\", \"embedding\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjusted-compound",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def generate_sentence_embedding(sentence, model, tokenizer):\n",
    "    # convert one headline to BERT input and generate embeddings\n",
    "    marked_text = \"[CLS] \" + str(sentence) + \" [SEP]\"\n",
    "\n",
    "    # Tokenize our sentence with the BERT tokenizer.\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "    # Map the token strings to their vocabulary indeces.\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "    # Mark each of the 22 tokens as belonging to sentence \"1\".\n",
    "    segments_ids = [1] * len(tokenized_text)\n",
    "\n",
    "    # Convert to pytorh and cut the tensor to max len: 512 \n",
    "    tokens_tensor = torch.tensor([indexed_tokens])[:, :512]\n",
    "    segments_tensors = torch.tensor([segments_ids])[:, :512]\n",
    "    \n",
    "    # Run the text through BERT, and collect all of the hidden states produced\n",
    "    # from all 12 layers. \n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor, segments_tensors, output_hidden_states=True)\n",
    "        hidden_states = outputs[2]\n",
    "\n",
    "    # Concatenate the tensors for all layers. We use `stack` here to\n",
    "    # create a new dimension in the tensor.\n",
    "    token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "\n",
    "    # Remove dimension 1, the \"batches\".\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "\n",
    "    # Swap dimensions 0 and 1.\n",
    "    token_embeddings = token_embeddings.permute(1,0,2)\n",
    "\n",
    "    # `token_vecs` is a tensor with shape [22 x 768]\n",
    "    token_vecs = hidden_states[-2][0]\n",
    "\n",
    "    # Calculate the average of all 22 token vectors.\n",
    "    sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "    \n",
    "    return sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-reggae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sent_embed = generate_sentence_embedding(df_headlines.headline.iloc[5], model, tokenizer)\n",
    "sent_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "armed-munich",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_headlines.loc[df_headlines.movie_id.str.contains(\"kmotr\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "obvious-programmer",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/8674 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/8674 [00:00<19:07,  7.56it/s]\u001b[A\n",
      "  0%|          | 3/8674 [00:00<17:52,  8.09it/s]\u001b[A\n",
      "  0%|          | 5/8674 [00:00<17:02,  8.48it/s]\u001b[A\n",
      "  0%|          | 6/8674 [00:00<17:38,  8.19it/s]\u001b[A\n",
      "  0%|          | 7/8674 [00:00<18:06,  7.98it/s]\u001b[A\n",
      "  0%|          | 8/8674 [00:00<18:18,  7.89it/s]\u001b[A\n",
      "  0%|          | 9/8674 [00:01<19:34,  7.38it/s]\u001b[A\n",
      "  0%|          | 10/8674 [00:01<19:28,  7.42it/s]\u001b[A\n",
      "  0%|          | 11/8674 [00:01<36:30,  3.95it/s]\u001b[A\n",
      "  0%|          | 12/8674 [00:01<31:18,  4.61it/s]\u001b[A\n",
      "  0%|          | 13/8674 [00:02<28:31,  5.06it/s]\u001b[A\n",
      "  0%|          | 14/8674 [00:02<24:36,  5.86it/s]\u001b[A\n",
      "  0%|          | 15/8674 [00:02<23:52,  6.04it/s]\u001b[A\n",
      "  0%|          | 16/8674 [00:02<22:20,  6.46it/s]\u001b[A\n",
      "  0%|          | 17/8674 [00:02<21:58,  6.56it/s]\u001b[A\n",
      "  0%|          | 18/8674 [00:02<22:25,  6.43it/s]\u001b[A\n",
      "  0%|          | 19/8674 [00:02<21:31,  6.70it/s]\u001b[A\n",
      "  0%|          | 20/8674 [00:02<19:47,  7.29it/s]\u001b[A\n",
      "  0%|          | 21/8674 [00:03<20:36,  7.00it/s]\u001b[A\n",
      "  0%|          | 22/8674 [00:03<19:00,  7.59it/s]\u001b[A\n",
      "  0%|          | 23/8674 [00:03<19:05,  7.55it/s]\u001b[A\n",
      "  0%|          | 24/8674 [00:03<18:00,  8.01it/s]\u001b[A\n",
      "  0%|          | 25/8674 [00:03<18:51,  7.64it/s]\u001b[A\n",
      "  0%|          | 26/8674 [00:03<18:56,  7.61it/s]\u001b[A\n",
      "  0%|          | 27/8674 [00:03<19:16,  7.48it/s]\u001b[A\n",
      "  0%|          | 28/8674 [00:04<20:13,  7.12it/s]\u001b[A\n",
      "  0%|          | 29/8674 [00:04<19:51,  7.25it/s]\u001b[A\n",
      "  0%|          | 30/8674 [00:04<19:39,  7.33it/s]\u001b[A\n",
      "  0%|          | 31/8674 [00:04<20:35,  7.00it/s]\u001b[A\n",
      "  0%|          | 32/8674 [00:04<20:11,  7.13it/s]\u001b[A\n",
      "  0%|          | 33/8674 [00:04<20:33,  7.00it/s]\u001b[A\n",
      "  0%|          | 34/8674 [00:04<21:07,  6.81it/s]\u001b[A\n",
      "  0%|          | 35/8674 [00:05<20:28,  7.03it/s]\u001b[A\n",
      "  0%|          | 36/8674 [00:05<20:14,  7.11it/s]\u001b[A\n",
      "  0%|          | 37/8674 [00:05<19:50,  7.25it/s]\u001b[A\n",
      "  0%|          | 38/8674 [00:05<20:36,  6.99it/s]\u001b[A\n",
      "  0%|          | 39/8674 [00:05<20:02,  7.18it/s]\u001b[A\n",
      "  0%|          | 40/8674 [00:05<19:42,  7.30it/s]\u001b[A\n",
      "  0%|          | 41/8674 [00:05<18:17,  7.86it/s]\u001b[A\n",
      "  0%|          | 42/8674 [00:06<19:29,  7.38it/s]\u001b[A\n",
      "  0%|          | 43/8674 [00:06<19:32,  7.36it/s]\u001b[A\n",
      "  1%|          | 44/8674 [00:06<19:11,  7.49it/s]\u001b[A\n",
      "  1%|          | 45/8674 [00:06<19:07,  7.52it/s]\u001b[A\n",
      "  1%|          | 46/8674 [00:06<19:33,  7.35it/s]\u001b[A\n",
      "  1%|          | 47/8674 [00:06<20:28,  7.02it/s]\u001b[A\n",
      "  1%|          | 48/8674 [00:06<21:07,  6.80it/s]\u001b[A\n",
      "  1%|          | 49/8674 [00:06<19:23,  7.41it/s]\u001b[A\n",
      "  1%|          | 50/8674 [00:07<18:10,  7.91it/s]\u001b[A\n",
      "  1%|          | 51/8674 [00:07<18:21,  7.83it/s]\u001b[A\n",
      "  1%|          | 52/8674 [00:07<19:20,  7.43it/s]\u001b[A\n",
      "  1%|          | 53/8674 [00:07<20:13,  7.10it/s]\u001b[A\n",
      "  1%|          | 54/8674 [00:07<18:40,  7.70it/s]\u001b[A\n",
      "  1%|          | 56/8674 [00:07<17:36,  8.16it/s]\u001b[A\n",
      "  1%|          | 57/8674 [00:07<18:01,  7.96it/s]\u001b[A\n",
      "  1%|          | 58/8674 [00:08<19:22,  7.41it/s]\u001b[A\n",
      "  1%|          | 59/8674 [00:08<19:14,  7.46it/s]\u001b[A\n",
      "  1%|          | 60/8674 [00:08<19:07,  7.51it/s]\u001b[A\n",
      "  1%|          | 61/8674 [00:08<17:55,  8.01it/s]\u001b[A\n",
      "  1%|          | 62/8674 [00:08<18:32,  7.74it/s]\u001b[A\n",
      "  1%|          | 63/8674 [00:08<18:54,  7.59it/s]\u001b[A\n",
      "  1%|          | 64/8674 [00:08<18:56,  7.57it/s]\u001b[A\n",
      "  1%|          | 65/8674 [00:09<18:57,  7.57it/s]\u001b[A\n",
      "  1%|          | 66/8674 [00:09<17:52,  8.02it/s]\u001b[A\n",
      "  1%|          | 67/8674 [00:09<18:13,  7.87it/s]\u001b[A\n",
      "  1%|          | 68/8674 [00:09<19:24,  7.39it/s]\u001b[A\n",
      "  1%|          | 69/8674 [00:09<19:18,  7.43it/s]\u001b[A\n",
      "  1%|          | 70/8674 [00:09<19:26,  7.38it/s]\u001b[A\n",
      "  1%|          | 71/8674 [00:09<19:21,  7.41it/s]\u001b[A\n",
      "  1%|          | 72/8674 [00:09<19:15,  7.45it/s]\u001b[A\n",
      "  1%|          | 73/8674 [00:10<19:04,  7.52it/s]\u001b[A\n",
      "  1%|          | 74/8674 [00:10<20:06,  7.13it/s]\u001b[A\n",
      "  1%|          | 75/8674 [00:10<19:49,  7.23it/s]\u001b[A\n",
      "  1%|          | 76/8674 [00:10<20:33,  6.97it/s]\u001b[A\n",
      "  1%|          | 77/8674 [00:10<20:05,  7.13it/s]\u001b[A\n",
      "  1%|          | 78/8674 [00:10<19:49,  7.23it/s]\u001b[A\n",
      "  1%|          | 79/8674 [00:10<19:47,  7.24it/s]\u001b[A\n",
      "  1%|          | 80/8674 [00:11<19:31,  7.34it/s]\u001b[A\n",
      "  1%|          | 81/8674 [00:11<19:17,  7.43it/s]\u001b[A\n",
      "  1%|          | 82/8674 [00:11<20:14,  7.08it/s]\u001b[A\n",
      "  1%|          | 83/8674 [00:11<19:55,  7.19it/s]\u001b[A\n",
      "  1%|          | 84/8674 [00:11<19:32,  7.33it/s]\u001b[A\n",
      "  1%|          | 85/8674 [00:11<20:22,  7.03it/s]\u001b[A\n",
      "  1%|          | 86/8674 [00:11<21:01,  6.81it/s]\u001b[A\n",
      "  1%|          | 87/8674 [00:12<21:25,  6.68it/s]\u001b[A\n",
      "  1%|          | 88/8674 [00:12<19:34,  7.31it/s]\u001b[A\n",
      "  1%|          | 89/8674 [00:12<19:24,  7.37it/s]\u001b[A\n",
      "  1%|          | 90/8674 [00:12<18:15,  7.83it/s]\u001b[A\n",
      "  1%|          | 91/8674 [00:12<19:37,  7.29it/s]\u001b[A\n",
      "  1%|          | 92/8674 [00:12<20:38,  6.93it/s]\u001b[A\n",
      "  1%|          | 93/8674 [00:12<21:17,  6.72it/s]\u001b[A\n",
      "  1%|          | 94/8674 [00:13<20:40,  6.92it/s]\u001b[A\n",
      "  1%|          | 95/8674 [00:13<21:05,  6.78it/s]\u001b[A\n",
      "  1%|          | 96/8674 [00:13<20:20,  7.03it/s]\u001b[A\n",
      "  1%|          | 97/8674 [00:13<19:51,  7.20it/s]\u001b[A\n",
      "  1%|          | 98/8674 [00:13<19:29,  7.33it/s]\u001b[A\n",
      "  1%|          | 99/8674 [00:13<20:28,  6.98it/s]\u001b[A\n",
      "  1%|          | 100/8674 [00:13<18:53,  7.56it/s]\u001b[A\n",
      "  1%|          | 101/8674 [00:14<19:47,  7.22it/s]\u001b[A\n",
      "  1%|          | 102/8674 [00:14<19:22,  7.38it/s]\u001b[A\n",
      "  1%|          | 103/8674 [00:14<20:11,  7.07it/s]\u001b[A\n",
      "  1%|          | 104/8674 [00:14<20:49,  6.86it/s]\u001b[A\n",
      "  1%|          | 105/8674 [00:14<21:34,  6.62it/s]\u001b[A\n",
      "  1%|          | 106/8674 [00:14<20:47,  6.87it/s]\u001b[A\n",
      "  1%|          | 107/8674 [00:14<20:05,  7.11it/s]\u001b[A\n",
      "  1%|          | 108/8674 [00:14<18:39,  7.65it/s]\u001b[A\n",
      "  1%|▏         | 109/8674 [00:15<18:40,  7.64it/s]\u001b[A\n",
      "  1%|▏         | 111/8674 [00:15<17:02,  8.37it/s]\u001b[A\n",
      "  1%|▏         | 112/8674 [00:15<18:29,  7.72it/s]\u001b[A\n",
      "  1%|▏         | 113/8674 [00:15<19:38,  7.26it/s]\u001b[A\n",
      "  1%|▏         | 114/8674 [00:15<20:21,  7.01it/s]\u001b[A\n",
      "  1%|▏         | 115/8674 [00:15<19:49,  7.20it/s]\u001b[A\n",
      "  1%|▏         | 116/8674 [00:16<20:32,  6.94it/s]\u001b[A\n",
      "  1%|▏         | 117/8674 [00:16<19:55,  7.15it/s]\u001b[A\n",
      "  1%|▏         | 118/8674 [00:16<19:52,  7.17it/s]\u001b[A\n",
      "  1%|▏         | 119/8674 [00:16<19:32,  7.30it/s]\u001b[A\n",
      "  1%|▏         | 120/8674 [00:16<20:22,  7.00it/s]\u001b[A\n",
      "  1%|▏         | 121/8674 [00:16<19:55,  7.16it/s]\u001b[A\n",
      "  1%|▏         | 122/8674 [00:16<20:36,  6.92it/s]\u001b[A\n",
      "  1%|▏         | 123/8674 [00:17<21:04,  6.76it/s]\u001b[A\n",
      "  1%|▏         | 124/8674 [00:17<19:14,  7.40it/s]\u001b[A\n",
      "  1%|▏         | 126/8674 [00:17<17:54,  7.95it/s]\u001b[A\n",
      "  1%|▏         | 127/8674 [00:17<17:06,  8.33it/s]\u001b[A\n",
      "  1%|▏         | 128/8674 [00:17<18:37,  7.65it/s]\u001b[A\n",
      "  1%|▏         | 129/8674 [00:17<19:38,  7.25it/s]\u001b[A\n",
      "  1%|▏         | 130/8674 [00:17<19:22,  7.35it/s]\u001b[A\n",
      "  2%|▏         | 131/8674 [00:18<20:14,  7.04it/s]\u001b[A\n",
      "  2%|▏         | 132/8674 [00:18<20:48,  6.84it/s]\u001b[A\n",
      "  2%|▏         | 133/8674 [00:18<21:07,  6.74it/s]\u001b[A\n",
      "  2%|▏         | 134/8674 [00:18<19:50,  7.17it/s]\u001b[A\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-227-20df822dad7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0membeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_headlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheadline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0membeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_sentence_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdf_headlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"embedding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdf_headlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../../../data/headlines_test.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36mgenerate_sentence_embedding\u001b[0;34m(sentence, model, tokenizer)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    879\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    883\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local-Pytorch-21.SIF/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, next_sentence_label, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m         \u001b[0msequence_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m         \u001b[0mprediction_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_relationship_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooled_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    879\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    883\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local-Pytorch-21.SIF/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sequence_output, pooled_output)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooled_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m         \u001b[0mprediction_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m         \u001b[0mseq_relationship_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_relationship\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mprediction_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_relationship_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    879\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    883\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local-Pytorch-21.SIF/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    879\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    883\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1756\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1759\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# for each film in headlines generate embeddings and save to headlines.csv\n",
    "embeds = []\n",
    "for h in tqdm(df_headlines.headline):\n",
    "    embeds.append(generate_sentence_embedding(h, model, tokenizer).tolist())\n",
    "df_headlines[\"embedding\"] = embeds\n",
    "df_headlines.to_csv(\"../../../data/headlines_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "rocky-casting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "class EmbedResSys(RecSysBase):\n",
    "    \"\"\"\n",
    "    System recommends unseen movies using embeddings\n",
    "    \n",
    "    csv_embed_path ... string path to a dataframe mapping movie_id to embedding\n",
    "    \"\"\"\n",
    "    def __init__(self, movies_df : pd.DataFrame, csv_embed_path : str = None):        \n",
    "        self.movies_df = movies_df\n",
    "        if csv_embed_path is None:\n",
    "#             super(EmbedResSys, self).__init__(movies_df)\n",
    "            self.device = \"cuda\"\n",
    "            self.prepare_model_tokenizer()           \n",
    "            self.df_embed = self.generate_embeddings()\n",
    "        else:\n",
    "            self.df_embed = pd.read_csv(csv_embed_path)\n",
    "            self.df_embed.embedding = self.df_embed.embedding.apply(ast.literal_eval)\n",
    "            \n",
    "        # pick those rows of the df_embed that correspond to the movies_df\n",
    "        self.df_embed = pd.merge(movies_df, self.df_embed, how='inner')[[\"movie_id\", \"embedding\"]]\n",
    "    \n",
    "        # target matrix of all embeddings for getting the similarity \n",
    "        self.target = torch.tensor(list(self.df_embed.embedding))\n",
    "        \n",
    "        self.index_to_movie_id = dict(enumerate(movies_df.movie_id.to_list()))\n",
    "    \n",
    "    \n",
    "    def recommend(self, user_history : List[str], n : int = 10, return_df : bool = False) -> List[str]:\n",
    "        \"\"\"Recommends unseen movies using embeddings from headlines.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        user_history : List[str]\n",
    "            A list of movie IDs\n",
    "\n",
    "        n : int\n",
    "            Recommends n movies, if set to an integer.\n",
    "            Default value None returns all the movies.\n",
    "        \"\"\"\n",
    "        # Take last k movies, join them into a single description and create a query.\n",
    "        k = 50 # TODO: should this be a customizable parameter? or should it be tuned?\n",
    "        last_k_movies = user_history[-k:]\n",
    "        # mean of the embeddings of th last k movies\n",
    "        query = torch.mean(torch.tensor([self.df_embed.loc[self.df_embed.movie_id == m][\"embedding\"].iloc[0] for m in user_history]), dim=0)\n",
    "        \n",
    "        similarities = list(enumerate(self.get_similarities(query)))\n",
    "        similarities = sorted(similarities, key=lambda item: item[1].item(), reverse=True)\n",
    "\n",
    "        result_ids, scores = [], []\n",
    "        for idx, sim in similarities:\n",
    "            movie_id = self.index_to_movie_id[idx]\n",
    "            if movie_id not in user_history:\n",
    "                result_ids.append(movie_id)\n",
    "                scores.append(sim.item())\n",
    "            \n",
    "            if len(result_ids) == n:\n",
    "                break\n",
    "\n",
    "        return pd.DataFrame({\n",
    "            'movie_id': result_ids,\n",
    "            f'score_{self.name}': scores\n",
    "        })\n",
    "    \n",
    "    \n",
    "    def generate_embeddings(self, save_dir=f\"../../../data\"):\n",
    "        df_embed = self.generate_descriptors()\n",
    "        \n",
    "        embeds = []\n",
    "        for h in tqdm(df_embed.descriptor):\n",
    "            embeds.append(self.generate_one_embedding(h))\n",
    "        df_embed[\"embedding\"] = embeds\n",
    "        \n",
    "        if save_dir:\n",
    "            df_embed.to_csv(save_dir+f\"/{self.name}_embeddings.csv\")\n",
    "        \n",
    "        return df_embed\n",
    "    \n",
    "    \n",
    "    def generate_one_embedding(self, sentence):\n",
    "        # convert one descriptor to BERT input and generate embeddings\n",
    "        marked_text = \"[CLS] \" + str(sentence) + \" [SEP]\"\n",
    "\n",
    "        # Tokenize our sentence with the BERT tokenizer.\n",
    "        tokenized_text = self.tokenizer.tokenize(marked_text)\n",
    "\n",
    "        # Map the token strings to their vocabulary indeces.\n",
    "        indexed_tokens = self.tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "        # Mark each of the 22 tokens as belonging to sentence \"1\".\n",
    "        segments_ids = [1] * len(tokenized_text)\n",
    "\n",
    "        # Convert to pytorh and cut the tensor to max len: 512 \n",
    "        tokens_tensor = torch.tensor([indexed_tokens])[:, :512].to(self.device)\n",
    "        segments_tensors = torch.tensor([segments_ids])[:, :512].to(self.device)\n",
    "\n",
    "        # Run the text through BERT, and collect all of the hidden states produced\n",
    "        # from all 12 layers. \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(tokens_tensor, segments_tensors, output_hidden_states=True)\n",
    "            hidden_states = outputs[2]\n",
    "\n",
    "        # Concatenate the tensors for all layers. We use `stack` here to\n",
    "        # create a new dimension in the tensor.\n",
    "        token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "\n",
    "        # Remove dimension 1, the \"batches\".\n",
    "        token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "\n",
    "        # Swap dimensions 0 and 1.\n",
    "        token_embeddings = token_embeddings.permute(1,0,2)\n",
    "\n",
    "        # `token_vecs` is a tensor with shape [22 x 768]\n",
    "        token_vecs = hidden_states[-2][0]\n",
    "\n",
    "        # Calculate the average of all 22 token vectors.\n",
    "        sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "\n",
    "        return sentence_embedding.tolist()\n",
    "\n",
    "    \n",
    "    def get_similarities(self, query):\n",
    "        return torch.nn.CosineSimilarity(dim=-1)(query, self.target)\n",
    "    \n",
    "    \n",
    "    def prepare_model_tokenizer(self):\n",
    "        self.model = AutoModelForPreTraining.from_pretrained(\"UWB-AIR/Czert-B-base-cased\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"UWB-AIR/Czert-B-base-cased\")\n",
    "        device = 'cuda' # 'cpu' alternatively\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "    \n",
    "    # conerts string representation of list to a torch tensor\n",
    "    def string_to_torch(self, string):\n",
    "        return torch.tensor([float(x) for x in string[1:-1].split(\",\")])\n",
    "\n",
    "    \n",
    "    def batch(self, iterable, n=1):\n",
    "        l = len(iterable)\n",
    "        for ndx in range(0, l, n):\n",
    "            yield iterable[ndx:min(ndx + n, l)]\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def generate_descriptors(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "described-jenny",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EmbedResSys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1342770cf5b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mHeadlineResSys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmbedResSys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \"\"\"\n\u001b[1;32m     13\u001b[0m     \u001b[0mSystem\u001b[0m \u001b[0mrecommends\u001b[0m \u001b[0munseen\u001b[0m \u001b[0mmovies\u001b[0m \u001b[0musing\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EmbedResSys' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import sys\n",
    "sys.path\n",
    "# sys.path.append('../../../../../Summarization')\n",
    "# from utils import add_special_tokens, generate_one_summary_fast\n",
    "\n",
    "# from utils import add_special_tokens, generate_one_summary_fast       #TODO\n",
    "from transformers import AutoTokenizer, AutoModelForPreTraining\n",
    "import torch\n",
    "\n",
    "class HeadlineResSys(EmbedResSys):\n",
    "    \"\"\"\n",
    "    System recommends unseen movies using embeddings\n",
    "    \n",
    "    csv_embed_path ... string path to a dataframe mapping movie_id to embedding\n",
    "    \"\"\"\n",
    "    def __init__(self, movies_df : pd.DataFrame, csv_embed_path : str = None):  \n",
    "     \n",
    "        super(HeadlineResSys, self).__init__(movies_df, csv_embed_path=csv_embed_path)        \n",
    "\n",
    "        \n",
    "    def generate_descriptors(self):\n",
    "        # load model\n",
    "        model = AutoModelForCausalLM.from_pretrained(\"MU-NLPC/CzeGPT-2\")\n",
    "\n",
    "        # put model into eval mode and on device\n",
    "        model.eval()\n",
    "        device = 'cuda' # 'cpu' alternatively\n",
    "        model.to(device)\n",
    "\n",
    "        # load and set tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"MU-NLPC/CzeGPT-2\")\n",
    "        special_tokens = {'sep_token':'<|sep|>'}\n",
    "        tokenizer.add_special_tokens(special_tokens)\n",
    "        tokenizer.model_max_length = 1024\n",
    "        \n",
    "        # for each description get a descriptor\n",
    "        descriptors = []\n",
    "        for i in tqdm(range(len(self.movies_df[\"description\"]))):\n",
    "            input_seq = movies_df.iloc[i][\"description\"]\n",
    "            descriptors.append(generate_one_summary_fast(input_seq, tokenizer, model, top_k=50, top_p=0.5, device=device, eos_stopping=True))\n",
    "\n",
    "        hdf = movies_df.head(len(descriptors))[[\"movie_id\"]]\n",
    "        hdf[\"descriptor\"] = descriptors\n",
    "        return hdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blocked-norway",
   "metadata": {},
   "source": [
    "### First sentence embedding\n",
    "\n",
    "This recommender takes the name of the movie and the first sentence, concatenates it and creates the embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "selective-register",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "class FirstSentResSys(EmbedResSys):\n",
    "    \"\"\"\n",
    "    System recommends unseen movies using embeddings\n",
    "    \n",
    "    csv_embed_path ... string path to a dataframe mapping movie_id to embedding\n",
    "    \"\"\"\n",
    "    def __init__(self, movies_df : pd.DataFrame, csv_embed_path : str = None):  \n",
    "     \n",
    "        super(FirstSentResSys, self).__init__(movies_df, csv_embed_path=csv_embed_path)        \n",
    "\n",
    "        \n",
    "    def generate_descriptors(self):        \n",
    "        # for each description get a descriptor\n",
    "        first_sent = self.movies_df.description.apply(lambda x: \" \".join(sent_tokenize(x)[:1]))\n",
    "        descriptors = list(self.movies_df.title.astype(str) + ' ' + first_sent)\n",
    "\n",
    "        hdf = self.movies_df[[\"movie_id\"]]\n",
    "        hdf[\"descriptor\"] = descriptors\n",
    "        return hdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "chicken-press",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.5 s, sys: 230 ms, total: 22.8 s\n",
      "Wall time: 22.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rcmnd = FirstSentResSys(movie_db, csv_embed_path=\"../../../data/FirstSentResSys_embeddings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcmnd = HeadlineResSys(movie_db, \"../../../data/HeadlineResSys_embeddings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "touched-destruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_history = [\"308348-pribeh-kmotra\", \"1645-kmotr-ii\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "capable-belle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>score_FirstSentResSys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12392-magnum-force</td>\n",
       "      <td>0.950929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7093-podezreni</td>\n",
       "      <td>0.949556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5317-cintamani-podvodnik</td>\n",
       "      <td>0.947838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5395-mechanicky-pomeranc</td>\n",
       "      <td>0.945152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>271458-zeme-bez-zakona</td>\n",
       "      <td>0.943781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5914-tenkrat-v-americe</td>\n",
       "      <td>0.943566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   movie_id  score_FirstSentResSys\n",
       "0        12392-magnum-force               0.950929\n",
       "1            7093-podezreni               0.949556\n",
       "2  5317-cintamani-podvodnik               0.947838\n",
       "3  5395-mechanicky-pomeranc               0.945152\n",
       "4    271458-zeme-bez-zakona               0.943781\n",
       "5    5914-tenkrat-v-americe               0.943566"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcmnd.recommend(user_history, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "conservative-pattern",
   "metadata": {},
   "outputs": [],
   "source": [
    "frst_df = pd.read_csv(\"../../../data/FirstSentResSys_embeddings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "turkish-david",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.8 s, sys: 168 ms, total: 22.9 s\n",
      "Wall time: 22.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "target = torch.tensor(list(frst_df.embedding.apply(ast.literal_eval)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "representative-nation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2351,  0.1156,  0.6456,  ..., -0.1213, -0.3023, -0.1100],\n",
       "        [ 0.2682,  0.1230,  0.1604,  ..., -0.3904, -0.5052,  0.1072],\n",
       "        [ 0.2351,  0.1156,  0.6456,  ..., -0.1213, -0.3023, -0.1100],\n",
       "        ...,\n",
       "        [ 0.4401, -0.0586, -0.1574,  ...,  0.0682, -0.3331, -0.2376],\n",
       "        [ 0.2497,  0.0128, -0.1463,  ..., -0.2329, -0.4552, -0.1454],\n",
       "        [ 0.1440,  0.1955, -0.6020,  ..., -0.0032, -0.5883, -0.1310]])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "attached-session",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `list(pd.merge(movie_db, pd.DataFrame({\"movie_id\": user_history}), how='inner')[[\"movie_id\"]][\"movie_id\"])` not found.\n",
      "CPU times: user 7.08 ms, sys: 327 µs, total: 7.4 ms\n",
      "Wall time: 6.41 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "[movie_db.loc[movie_db.movie_id == m][\"movie_id\"].iloc[0] for m in user_history]\n",
    "?list(pd.merge(movie_db, pd.DataFrame({\"movie_id\": user_history}), how='inner')[[\"movie_id\"]][\"movie_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "unavailable-petite",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to generate with BERT using batches\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"UWB-AIR/Czert-B-base-cased\")\n",
    "model = AutoModelForPreTraining.from_pretrained(\"UWB-AIR/Czert-B-base-cased\")\n",
    "model.to(\"cuda\")\n",
    "model.eval()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "brave-consultancy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n",
      "torch.Size([1, 512])\n",
      "CPU times: user 82.9 ms, sys: 9.13 ms, total: 92 ms\n",
      "Wall time: 86.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "device = \"cuda\"\n",
    "model.to(device)\n",
    "tokens_tensors = torch.stack([torch.randint(0,10000, (512,))] *1).to(device)\n",
    "print(tokens_tensors.shape)\n",
    "segments_tensors = torch.tensor([512*[1]]*1).to(device)\n",
    "print(segments_tensors.shape)\n",
    "with torch.no_grad():\n",
    "    outputs = model(tokens_tensors, segments_tensors, output_hidden_states=True)\n",
    "    hidden_states = outputs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "desirable-minimum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 512, 768])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "danish-battlefield",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75613-hercule-poirot_498504-serie-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>613789-obeti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75613-hercule-poirot_498507-serie-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>350930-krtek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33863-bajaja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8669</th>\n",
       "      <td>232938-hobit-neocekavana-cesta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>227786-interstellar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>223734-temny-rytir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>254156-pocatek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>228329-avatar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8674 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  movie_id\n",
       "0      75613-hercule-poirot_498504-serie-9\n",
       "1                             613789-obeti\n",
       "2     75613-hercule-poirot_498507-serie-12\n",
       "3                             350930-krtek\n",
       "4                             33863-bajaja\n",
       "...                                    ...\n",
       "8669        232938-hobit-neocekavana-cesta\n",
       "8670                   227786-interstellar\n",
       "8671                    223734-temny-rytir\n",
       "8672                        254156-pocatek\n",
       "8673                         228329-avatar\n",
       "\n",
       "[8674 rows x 1 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    def generate_one_embedding(self, sentence):\n",
    "        # convert one descriptor to BERT input and generate embeddings\n",
    "        marked_text = \"[CLS] \" + str(sentence) + \" [SEP]\"\n",
    "\n",
    "        # Tokenize our sentence with the BERT tokenizer.\n",
    "        tokenized_text = self.tokenizer.tokenize(marked_text)\n",
    "\n",
    "        # Map the token strings to their vocabulary indeces.\n",
    "        indexed_tokens = self.tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "        # Mark each of the 22 tokens as belonging to sentence \"1\".\n",
    "        segments_ids = [1] * len(tokenized_text)\n",
    "\n",
    "        # Convert to pytorh and cut the tensor to max len: 512 \n",
    "        tokens_tensor = torch.tensor([indexed_tokens])[:, :512]\n",
    "        segments_tensors = torch.tensor([segments_ids])[:, :512]\n",
    "\n",
    "        # Run the text through BERT, and collect all of the hidden states produced\n",
    "        # from all 12 layers. \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(tokens_tensor, segments_tensors, output_hidden_states=True)\n",
    "            hidden_states = outputs[2]\n",
    "\n",
    "        # Concatenate the tensors for all layers. We use `stack` here to\n",
    "        # create a new dimension in the tensor.\n",
    "        token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "\n",
    "        # Remove dimension 1, the \"batches\".\n",
    "        token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "\n",
    "        # Swap dimensions 0 and 1.\n",
    "        token_embeddings = token_embeddings.permute(1,0,2)\n",
    "\n",
    "        # `token_vecs` is a tensor with shape [22 x 768]\n",
    "        token_vecs = hidden_states[-2][0]\n",
    "\n",
    "        # Calculate the average of all 22 token vectors.\n",
    "        sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "\n",
    "        return sentence_embedding.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "permanent-banking",
   "metadata": {},
   "source": [
    "---\n",
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "australian-catalyst",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Hercule Poirot Malý belgický detektiv Hercule ...\n",
       "1       Oběti Na televizní obrazovku se vrací cyklus  ...\n",
       "2       Hercule Poirot Malý belgický detektiv Hercule ...\n",
       "3                                                  Krtek \n",
       "4       Bajaja Jiří Trnka natočil v roce 1950 volně po...\n",
       "                              ...                        \n",
       "8669    Hobit: Neočekávaná cesta Film sleduje cestu hl...\n",
       "8670    Interstellar Příběh se odehrává v nepříliš vzd...\n",
       "8671    Temný rytíř Další Batmanovo dobrodružství začí...\n",
       "8672    Počátek Dom Cobb (Leonardo DiCaprio) je velmi ...\n",
       "8673    Avatar Avatar před námi otevírá neuvěřitelný s...\n",
       "Length: 8674, dtype: object"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "divided-disorder",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>genres</th>\n",
       "      <th>countries</th>\n",
       "      <th>year</th>\n",
       "      <th>creators</th>\n",
       "      <th>avg_stars</th>\n",
       "      <th>num_ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8018</th>\n",
       "      <td>9498-matrix-revolutions</td>\n",
       "      <td>Matrix Revolutions</td>\n",
       "      <td>Ve výbušné závěrečné kapitole trilogie Matrix ...</td>\n",
       "      <td>[Akční, Sci-Fi]</td>\n",
       "      <td>[USA, Austrálie]</td>\n",
       "      <td>2003</td>\n",
       "      <td>[Keanu Reeves, Laurence Fishburne, Carrie-Anne...</td>\n",
       "      <td>3.435927</td>\n",
       "      <td>874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8093</th>\n",
       "      <td>9497-matrix-reloaded</td>\n",
       "      <td>Matrix Reloaded</td>\n",
       "      <td>Druhé pokračování trilogie  nás opět zavede do...</td>\n",
       "      <td>[Akční, Sci-Fi]</td>\n",
       "      <td>[USA, Austrálie]</td>\n",
       "      <td>2003</td>\n",
       "      <td>[Keanu Reeves, Laurence Fishburne, Carrie-Anne...</td>\n",
       "      <td>3.713519</td>\n",
       "      <td>932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8628</th>\n",
       "      <td>9499-matrix</td>\n",
       "      <td>The Matrix</td>\n",
       "      <td>Za vším hledej Matrix. Zdál se vám někdy sen, ...</td>\n",
       "      <td>[Akční, Sci-Fi]</td>\n",
       "      <td>[USA]</td>\n",
       "      <td>1999</td>\n",
       "      <td>[Keanu Reeves, Laurence Fishburne, Carrie-Anne...</td>\n",
       "      <td>4.685115</td>\n",
       "      <td>2096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7675</th>\n",
       "      <td>1646-kmotr-iii</td>\n",
       "      <td>Kmotr III</td>\n",
       "      <td>Člověk financí a politiky. Al Pacino v hlavní ...</td>\n",
       "      <td>[Drama, Krimi]</td>\n",
       "      <td>[USA]</td>\n",
       "      <td>1990</td>\n",
       "      <td>[Al Pacino, Diane Keaton, Talia Shire, Francis...</td>\n",
       "      <td>4.309144</td>\n",
       "      <td>689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8083</th>\n",
       "      <td>1645-kmotr-ii</td>\n",
       "      <td>Kmotr II</td>\n",
       "      <td>Jsme větší než U. S. Steel. Al Pacino a Robert...</td>\n",
       "      <td>[Drama, Krimi]</td>\n",
       "      <td>[USA]</td>\n",
       "      <td>1974</td>\n",
       "      <td>[Al Pacino, Robert Duvall, Diane Keaton, Franc...</td>\n",
       "      <td>4.490811</td>\n",
       "      <td>925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8614</th>\n",
       "      <td>1644-kmotr</td>\n",
       "      <td>Kmotr</td>\n",
       "      <td>Kmotr je příběhem newyorské mafiánské rodiny C...</td>\n",
       "      <td>[Drama, Krimi]</td>\n",
       "      <td>[USA]</td>\n",
       "      <td>1972</td>\n",
       "      <td>[Marlon Brando, Al Pacino, James Caan, Francis...</td>\n",
       "      <td>4.594678</td>\n",
       "      <td>1954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>227786-interstellar</td>\n",
       "      <td>Interstellar</td>\n",
       "      <td>Příběh se odehrává v nepříliš vzdálené budoucn...</td>\n",
       "      <td>[Sci-Fi, Dobrodružný, Drama]</td>\n",
       "      <td>[USA, Velká Británie, Kanada]</td>\n",
       "      <td>2014</td>\n",
       "      <td>[Matthew McConaughey, Anne Hathaway, Jessica C...</td>\n",
       "      <td>4.072779</td>\n",
       "      <td>3174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>223734-temny-rytir</td>\n",
       "      <td>Temný rytíř</td>\n",
       "      <td>Další Batmanovo dobrodružství začíná. Jeho pro...</td>\n",
       "      <td>[Akční, Drama, Krimi, Thriller]</td>\n",
       "      <td>[USA, Velká Británie]</td>\n",
       "      <td>2008</td>\n",
       "      <td>[Christian Bale, Heath Ledger, Aaron Eckhart, ...</td>\n",
       "      <td>4.559151</td>\n",
       "      <td>3770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>254156-pocatek</td>\n",
       "      <td>Počátek</td>\n",
       "      <td>Dom Cobb (Leonardo DiCaprio) je velmi zkušený ...</td>\n",
       "      <td>[Akční, Sci-Fi, Thriller, Mysteriózní, Dobrodr...</td>\n",
       "      <td>[USA, Velká Británie]</td>\n",
       "      <td>2010</td>\n",
       "      <td>[Leonardo DiCaprio, Joseph Gordon-Levitt, Elli...</td>\n",
       "      <td>4.368000</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     movie_id               title  \\\n",
       "8018  9498-matrix-revolutions  Matrix Revolutions   \n",
       "8093     9497-matrix-reloaded     Matrix Reloaded   \n",
       "8628              9499-matrix          The Matrix   \n",
       "7675           1646-kmotr-iii           Kmotr III   \n",
       "8083            1645-kmotr-ii            Kmotr II   \n",
       "8614               1644-kmotr               Kmotr   \n",
       "8670      227786-interstellar        Interstellar   \n",
       "8671       223734-temny-rytir         Temný rytíř   \n",
       "8672           254156-pocatek             Počátek   \n",
       "\n",
       "                                            description  \\\n",
       "8018  Ve výbušné závěrečné kapitole trilogie Matrix ...   \n",
       "8093  Druhé pokračování trilogie  nás opět zavede do...   \n",
       "8628  Za vším hledej Matrix. Zdál se vám někdy sen, ...   \n",
       "7675  Člověk financí a politiky. Al Pacino v hlavní ...   \n",
       "8083  Jsme větší než U. S. Steel. Al Pacino a Robert...   \n",
       "8614  Kmotr je příběhem newyorské mafiánské rodiny C...   \n",
       "8670  Příběh se odehrává v nepříliš vzdálené budoucn...   \n",
       "8671  Další Batmanovo dobrodružství začíná. Jeho pro...   \n",
       "8672  Dom Cobb (Leonardo DiCaprio) je velmi zkušený ...   \n",
       "\n",
       "                                                 genres  \\\n",
       "8018                                    [Akční, Sci-Fi]   \n",
       "8093                                    [Akční, Sci-Fi]   \n",
       "8628                                    [Akční, Sci-Fi]   \n",
       "7675                                     [Drama, Krimi]   \n",
       "8083                                     [Drama, Krimi]   \n",
       "8614                                     [Drama, Krimi]   \n",
       "8670                       [Sci-Fi, Dobrodružný, Drama]   \n",
       "8671                    [Akční, Drama, Krimi, Thriller]   \n",
       "8672  [Akční, Sci-Fi, Thriller, Mysteriózní, Dobrodr...   \n",
       "\n",
       "                          countries  year  \\\n",
       "8018               [USA, Austrálie]  2003   \n",
       "8093               [USA, Austrálie]  2003   \n",
       "8628                          [USA]  1999   \n",
       "7675                          [USA]  1990   \n",
       "8083                          [USA]  1974   \n",
       "8614                          [USA]  1972   \n",
       "8670  [USA, Velká Británie, Kanada]  2014   \n",
       "8671          [USA, Velká Británie]  2008   \n",
       "8672          [USA, Velká Británie]  2010   \n",
       "\n",
       "                                               creators  avg_stars  \\\n",
       "8018  [Keanu Reeves, Laurence Fishburne, Carrie-Anne...   3.435927   \n",
       "8093  [Keanu Reeves, Laurence Fishburne, Carrie-Anne...   3.713519   \n",
       "8628  [Keanu Reeves, Laurence Fishburne, Carrie-Anne...   4.685115   \n",
       "7675  [Al Pacino, Diane Keaton, Talia Shire, Francis...   4.309144   \n",
       "8083  [Al Pacino, Robert Duvall, Diane Keaton, Franc...   4.490811   \n",
       "8614  [Marlon Brando, Al Pacino, James Caan, Francis...   4.594678   \n",
       "8670  [Matthew McConaughey, Anne Hathaway, Jessica C...   4.072779   \n",
       "8671  [Christian Bale, Heath Ledger, Aaron Eckhart, ...   4.559151   \n",
       "8672  [Leonardo DiCaprio, Joseph Gordon-Levitt, Elli...   4.368000   \n",
       "\n",
       "      num_ratings  \n",
       "8018          874  \n",
       "8093          932  \n",
       "8628         2096  \n",
       "7675          689  \n",
       "8083          925  \n",
       "8614         1954  \n",
       "8670         3174  \n",
       "8671         3770  \n",
       "8672         4000  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_matrix = movie_db[movie_db['movie_id'].str.contains('matrix')].tail(3)\n",
    "df_kmotr = movie_db[movie_db['title'].str.contains('Kmotr')].tail(3)\n",
    "df_nolan = movie_db[movie_db.creators.map(set(['Christopher Nolan']).issubset)].tail(3)\n",
    "\n",
    "test_df = pd.concat([df_matrix, df_kmotr, df_nolan])\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "adult-aggregate",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_test2 = HeadlineResSys(test_df, \"../../../data/headlines_list.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "engaging-combine",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "8614",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-263-4d63f58751e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mmovie\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrs_test2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecommend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'1644-kmotr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{sim:.4f}: {movie}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-260-d858b3ebe25c>\u001b[0m in \u001b[0;36mrecommend\u001b[0;34m(self, user_history, n, return_df)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msimilarities\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mmovie_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_to_movie_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmovie_id\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muser_history\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mmovie_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 8614"
     ]
    }
   ],
   "source": [
    "for movie, sim in rs_test2.recommend(['1644-kmotr']):\n",
    "    print(f'{sim:.4f}: {movie}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ruled-character",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1377: 9498-matrix-revolutions\n",
      "0.0734: 9497-matrix-reloaded\n",
      "0.0241: 1646-kmotr-iii\n",
      "0.0179: 1645-kmotr-ii\n",
      "0.0156: 254156-pocatek\n",
      "0.0144: 223734-temny-rytir\n",
      "0.0138: 227786-interstellar\n",
      "0.0126: 1644-kmotr\n"
     ]
    }
   ],
   "source": [
    "for movie, sim in rs_test2.recommend(['9499-matrix']):\n",
    "    print(f'{sim:.4f}: {movie}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "absent-spirituality",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyspark\n",
    "#!pip install spark-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designing-footage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "from sparknlp.pretrained import LemmatizerModel\n",
    "\n",
    "lemmatizer = LemmatizerModel.pretrained(\"lemma\", \"cs\")\\\n",
    "                .setInputCols([\"token\"])\\\n",
    "                .setOutputCol(\"lemma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-stroke",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install simplemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-petersburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "import simplemma\n",
    "\n",
    "langdata = simplemma.load_data('cs')\n",
    "\n",
    "for w in ['žebráci', 'žebral']:\n",
    "    lemma = simplemma.lemmatize(w, langdata)\n",
    "    stem = cz_stem(lemma)\n",
    "    print(f'{w} -> {lemma} -> {stem}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-field",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_popularity = movie_db.genres.explode().value_counts().sort_values(ascending=False)\n",
    "genre_popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-ordinary",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wordcloud\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "item_count_list_genres = analyse_freq(movies['genres'])\n",
    "genres, genre_counts = [list(t) for t in zip(*item_count_list_genres)]\n",
    "\n",
    "wc = wordcloud.WordCloud(background_color='white')\n",
    "wc.generate_from_frequencies(dict(zip(genres, genre_counts)))\n",
    "\n",
    "plt.imshow(wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "prescription-speech",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_headlines2 = pd.read_csv(\"../../../data/headlines_list.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "scenic-prince",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>headline</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>75613-hercule-poirot_498504-serie-9</td>\n",
       "      <td>Scotland Yard - nový detektiv?</td>\n",
       "      <td>[-0.5625672340393066, -0.47168660163879395, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>613789-obeti</td>\n",
       "      <td>Česká televize</td>\n",
       "      <td>[0.1335097700357437, 0.41292598843574524, 0.61...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>75613-hercule-poirot_498507-serie-12</td>\n",
       "      <td>Scotland Yard v novém kabátě</td>\n",
       "      <td>[-0.7068173885345459, -0.2617079019546509, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>350930-krtek</td>\n",
       "      <td>že jsem se narodil</td>\n",
       "      <td>[0.46434155106544495, 0.07884159684181213, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>33863-bajaja</td>\n",
       "      <td>Česká pohádka Bajaja se vrátila do Prahy</td>\n",
       "      <td>[0.06880209594964981, 0.19066403806209564, 0.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8669</th>\n",
       "      <td>8669</td>\n",
       "      <td>232938-hobit-neocekavana-cesta</td>\n",
       "      <td>Easter eggs: Bilbo Pytlík</td>\n",
       "      <td>[-0.050285954028367996, 0.13156619668006897, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>8670</td>\n",
       "      <td>227786-interstellar</td>\n",
       "      <td>Ulice 1169-1708: Červí díra</td>\n",
       "      <td>[0.585819661617279, 0.2834097743034363, 0.4016...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>8671</td>\n",
       "      <td>223734-temny-rytir</td>\n",
       "      <td>Ordinace v růžové zahradě 39: Poslední kapka</td>\n",
       "      <td>[0.2733287811279297, -0.38519376516342163, 1.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>8672</td>\n",
       "      <td>254156-pocatek</td>\n",
       "      <td>Ukradl myšlenky a teď se mu nabízí možnost vyk...</td>\n",
       "      <td>[0.0461638942360878, 0.14224864542484283, 0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>8673</td>\n",
       "      <td>228329-avatar</td>\n",
       "      <td>Avatar - svět plný života a nenávisti</td>\n",
       "      <td>[0.06364362686872482, 0.02668917365372181, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8674 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                              movie_id  \\\n",
       "0              0   75613-hercule-poirot_498504-serie-9   \n",
       "1              1                          613789-obeti   \n",
       "2              2  75613-hercule-poirot_498507-serie-12   \n",
       "3              3                          350930-krtek   \n",
       "4              4                          33863-bajaja   \n",
       "...          ...                                   ...   \n",
       "8669        8669        232938-hobit-neocekavana-cesta   \n",
       "8670        8670                   227786-interstellar   \n",
       "8671        8671                    223734-temny-rytir   \n",
       "8672        8672                        254156-pocatek   \n",
       "8673        8673                         228329-avatar   \n",
       "\n",
       "                                               headline  \\\n",
       "0                        Scotland Yard - nový detektiv?   \n",
       "1                                        Česká televize   \n",
       "2                          Scotland Yard v novém kabátě   \n",
       "3                                    že jsem se narodil   \n",
       "4              Česká pohádka Bajaja se vrátila do Prahy   \n",
       "...                                                 ...   \n",
       "8669                          Easter eggs: Bilbo Pytlík   \n",
       "8670                        Ulice 1169-1708: Červí díra   \n",
       "8671       Ordinace v růžové zahradě 39: Poslední kapka   \n",
       "8672  Ukradl myšlenky a teď se mu nabízí možnost vyk...   \n",
       "8673              Avatar - svět plný života a nenávisti   \n",
       "\n",
       "                                              embedding  \n",
       "0     [-0.5625672340393066, -0.47168660163879395, 0....  \n",
       "1     [0.1335097700357437, 0.41292598843574524, 0.61...  \n",
       "2     [-0.7068173885345459, -0.2617079019546509, 0.3...  \n",
       "3     [0.46434155106544495, 0.07884159684181213, 0.0...  \n",
       "4     [0.06880209594964981, 0.19066403806209564, 0.7...  \n",
       "...                                                 ...  \n",
       "8669  [-0.050285954028367996, 0.13156619668006897, 0...  \n",
       "8670  [0.585819661617279, 0.2834097743034363, 0.4016...  \n",
       "8671  [0.2733287811279297, -0.38519376516342163, 1.0...  \n",
       "8672  [0.0461638942360878, 0.14224864542484283, 0.08...  \n",
       "8673  [0.06364362686872482, 0.02668917365372181, 0.0...  \n",
       "\n",
       "[8674 rows x 4 columns]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_headlines2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "experimental-parish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-3.2247e-01',\n",
       " ' -1.6037e-01',\n",
       " ' -2.7747e-02',\n",
       " '  2.2188e-01',\n",
       " '  2.2052e-01',\n",
       " '\\n        -3.9928e-01',\n",
       " ' -3.4213e-01',\n",
       " ' -4.7073e-01',\n",
       " '  3.7822e-01',\n",
       " ' -5.2162e-01',\n",
       " '\\n         2.2698e-02',\n",
       " ' -2.6662e-01',\n",
       " '  9.6309e-02',\n",
       " ' -7.1487e-01',\n",
       " ' -4.7563e-01',\n",
       " '\\n         1.8311e-01',\n",
       " '  1.3808e-02',\n",
       " '  6.4929e-01',\n",
       " '  5.8477e-02',\n",
       " '  1.0346e-01',\n",
       " '\\n        -6.8578e-01',\n",
       " '  6.7290e-01',\n",
       " ' -5.1883e-01',\n",
       " ' -1.9852e-01',\n",
       " '  2.9400e-02',\n",
       " '\\n         4.0206e-01',\n",
       " '  9.8511e-02',\n",
       " ' -2.7132e-01',\n",
       " '  2.0048e-01',\n",
       " ' -7.0647e-02',\n",
       " '\\n         5.6653e-01',\n",
       " '  5.1893e-01',\n",
       " ' -2.5024e-01',\n",
       " '  4.2888e-01',\n",
       " ' -5.9884e-03',\n",
       " '\\n        -3.1353e-01',\n",
       " '  7.6915e-01',\n",
       " '  7.7918e-01',\n",
       " '  1.9785e-01',\n",
       " ' -6.7552e-01',\n",
       " '\\n         4.6639e-02',\n",
       " '  1.0574e+00',\n",
       " ' -9.5063e-01',\n",
       " ' -1.4573e-01',\n",
       " ' -1.6618e-01',\n",
       " '\\n        -7.8475e-02',\n",
       " ' -1.4015e-01',\n",
       " ' -2.4147e+00',\n",
       " ' -5.7294e-01',\n",
       " '  9.1124e-01',\n",
       " '\\n        -4.8365e-01',\n",
       " ' -3.2236e-01',\n",
       " ' -2.8448e-01',\n",
       " ' -1.1636e-02',\n",
       " ' -9.7421e-01',\n",
       " '\\n        -5.9065e-01',\n",
       " '  1.6998e-01',\n",
       " ' -6.0986e-01',\n",
       " ' -1.5445e-01',\n",
       " ' -2.2779e-01',\n",
       " '\\n         4.7322e-01',\n",
       " ' -2.0147e-01',\n",
       " '  5.8252e-01',\n",
       " ' -6.5007e-02',\n",
       " ' -2.8424e-01',\n",
       " '\\n        -3.0399e-01',\n",
       " ' -1.9859e-01']"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "a = \"[-3.2247e-01, -1.6037e-01, -2.7747e-02,  2.2188e-01,  2.2052e-01,\\n        -3.9928e-01, -3.4213e-01, -4.7073e-01,  3.7822e-01, -5.2162e-01,\\n         2.2698e-02, -2.6662e-01,  9.6309e-02, -7.1487e-01, -4.7563e-01,\\n         1.8311e-01,  1.3808e-02,  6.4929e-01,  5.8477e-02,  1.0346e-01,\\n        -6.8578e-01,  6.7290e-01, -5.1883e-01, -1.9852e-01,  2.9400e-02,\\n         4.0206e-01,  9.8511e-02, -2.7132e-01,  2.0048e-01, -7.0647e-02,\\n         5.6653e-01,  5.1893e-01, -2.5024e-01,  4.2888e-01, -5.9884e-03,\\n        -3.1353e-01,  7.6915e-01,  7.7918e-01,  1.9785e-01, -6.7552e-01,\\n         4.6639e-02,  1.0574e+00, -9.5063e-01, -1.4573e-01, -1.6618e-01,\\n        -7.8475e-02, -1.4015e-01, -2.4147e+00, -5.7294e-01,  9.1124e-01,\\n        -4.8365e-01, -3.2236e-01, -2.8448e-01, -1.1636e-02, -9.7421e-01,\\n        -5.9065e-01,  1.6998e-01, -6.0986e-01, -1.5445e-01, -2.2779e-01,\\n         4.7322e-01, -2.0147e-01,  5.8252e-01, -6.5007e-02, -2.8424e-01,\\n        -3.0399e-01, -1.9859e-01]\"\n",
    "[float(x) for x in a[1:-1].split(\",\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-middle",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
